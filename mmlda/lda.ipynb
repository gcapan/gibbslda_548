{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext line_profiler\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.sparse as spar\n",
    "import scipy.special as spec\n",
    "import sys\n",
    "from matplotlib import pyplot as plt\n",
    "from lda import LDA\n",
    "from sklearn.decomposition import LatentDirichletAllocation as SKLDA\n",
    "\n",
    "import cProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "M = 100\n",
    "V = 1000\n",
    "X = np.random.binomial(1,.3, size=M*V).reshape(M,V)\n",
    "X = spar.csr_matrix(X, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For even a reasonable setup like 10K vocabulary, 5K documents and 20 topics, the size of the tensor indexed by\n",
    "# <document, word, topic> simply explodes to 7.5G. This is why we can't explicitly keep all of $\\phi$ in the memory.\n",
    "# Instead, we iterate over the documents one by one, and accumulate the phi parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lda = LDA()\n",
    "#cProfile.run(\"lda.fit(X)\")\n",
    "%lprun -f lda.fit lda.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#b, g = lda.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "ng = fetch_20newsgroups(subset='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ng.filenames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vec = CountVectorizer(max_df=.7, min_df=20)\n",
    "ngvec = vec.fit_transform(ng.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%lprun lda.fit(ngvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Epoch: 1\n",
      "Epoch: 2\n",
      "Epoch: 3\n",
      "Epoch: 4\n",
      "Epoch: 5\n",
      "Epoch: 6\n",
      "Epoch: 7\n",
      "Epoch: 8\n",
      "Epoch: 9\n",
      "CPU times: user 3.99 s, sys: 997 ms, total: 4.99 s\n",
      "Wall time: 3min 41s\n"
     ]
    }
   ],
   "source": [
    "lda = LDA(n_jobs=8)\n",
    "%time b, g = lda.fit(ngvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lookup = lambda x : [k for k, v in vec.vocabulary_.items() if v == x]\n",
    "\n",
    "def topic_summaries(b):\n",
    "    bs = b.argsort()[:,-50:]\n",
    "    for i in range(5):\n",
    "        print \"Topic\", i\n",
    "        words = []\n",
    "        for j in range(bs.shape[1]):\n",
    "            words.append(lookup(bs[i,j])[0])\n",
    "        print \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sklda = SKLDA(n_topics=5, learning_method=\"batch\", verbose=True)\n",
    "sklda.fit(ngvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topic_summaries(sklda.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0\n",
      "don by some all has any know like up just cs so reply me will one ca distribution how about get at what there as would was com but do an are they university if this or not can on with be you writes have edu re nntp posting host\n",
      "Topic 1\n",
      "been like do me some has an only were can out with think would he com more just there people don no at we one so your or by about have who my all as they what edu if was on be re are but you writes this article not\n",
      "Topic 2\n",
      "thanks just edu article system writes about only know like me up all no at get does by your would one has using which so what how some my will as do there any are you com use re but be an not if have or with can on this\n",
      "Topic 3\n",
      "they public against today 1993 into than not over do one we or there during may has american people after would us national world also new two who now first these re be are its at years on been which was other have their were an as with government by\n",
      "Topic 4\n",
      "drive so 16 as computer will 10 new am know about would out mail anyone like has reply one please not was thanks writes can all usa com any me be but distribution are host posting nntp if or article my at this you re have with on university edu\n"
     ]
    }
   ],
   "source": [
    "topic_summaries(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.product(ngvec.shape) * 8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit ngvec.indices[ngvec.indptr[14]:ngvec.indptr[14+1]]\n",
    "%timeit ngvec[14, :].nonzero()[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
