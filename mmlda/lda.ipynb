{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext line_profiler\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.sparse as spar\n",
    "import scipy.special as spec\n",
    "import sys\n",
    "from matplotlib import pyplot as plt\n",
    "from lda import LDA, _doc_update, _slice_doc_update\n",
    "from sklearn.decomposition import LatentDirichletAllocation as SKLDA\n",
    "\n",
    "import pickle\n",
    "import cProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "M = 100\n",
    "V = 1000\n",
    "X = np.random.binomial(1,.3, size=M*V).reshape(M,V)\n",
    "X = spar.csr_matrix(X, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For even a reasonable setup like 10K vocabulary, 5K documents and 20 topics, the size of the tensor indexed by\n",
    "# <document, word, topic> simply explodes to 7.5G. This is why we can't explicitly keep all of $\\phi$ in the memory.\n",
    "# Instead, we iterate over the documents one by one, and accumulate the phi parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "ng = fetch_20newsgroups(subset='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vec = CountVectorizer(max_df=.7, min_df=20, stop_words=\"english\")\n",
    "ngvec = vec.fit_transform(ng.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Epoch: 1\n",
      "Epoch: 2\n",
      "Epoch: 3\n",
      "Epoch: 4\n",
      "Epoch: 5\n",
      "Epoch: 6\n",
      "Epoch: 7\n",
      "Epoch: 8\n",
      "Epoch: 9\n",
      "CPU times: user 3.23 s, sys: 1.18 s, total: 4.42 s\n",
      "Wall time: 3min 40s\n"
     ]
    }
   ],
   "source": [
    "lda = LDA(K=10, n_jobs=8)\n",
    "%time b, g = lda.fit(ngvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%lprun -f _slice_doc_update lda.fit(ngvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lookup = lambda x : [k for k, v in vec.vocabulary_.items() if v == x]\n",
    "\n",
    "def topic_summaries(b):\n",
    "    bs = b.argsort()[:,-50:]\n",
    "    for i in range(10):\n",
    "        print \"Topic\", i\n",
    "        words = []\n",
    "        for j in range(bs.shape[1]):\n",
    "            words.append(lookup(bs[i,j])[0])\n",
    "        print \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print ng.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sklda = SKLDA(n_topics=5, learning_method=\"batch\", verbose=True)\n",
    "sklda.fit(ngvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topic_summaries(sklda.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0\n",
      "ve truth wrong different university christ faith religion thing doesn read want right man said reason church world mean evidence christians really fact did things bible true life point make christian question time good way jesus believe like know say does article just com think don writes people god edu\n",
      "Topic 1\n",
      "cliff unt 1k 17 km fr morris edu mpg hi bk mv colin 75 nh gi ct 3d 86 lc air distribution bu app kindly lk ua bc hz 14 ne im end tm p2 meg sg ai wm 34 su lu ub wa bd hst pl bj uw max\n",
      "Topic 2\n",
      "chicago did roger runs second gm 12 15 won 20 division canada nntp host com best time toronto posting just 00 better player 25 new teams like vs cs 10 nhl baseball don league think university win good article players season writes hockey play games year ca team game edu\n",
      "Topic 3\n",
      "oh 13 don 17 15 __ magnus john acs gmt freenet columbia steve david virginia new cso org sun world mail like computer thanks cmu cwru apr cleveland netcom just andrew ohio know ca uiuc cc news usa state distribution cs reply nntp host university posting article writes com edu\n",
      "Topic 4\n",
      "think used legal org number crime posting escrow united technology administration congress case private house policy does make federal privacy control national information jews edu article american writes chip security states use mr clinton new right rights israeli key clipper gun state president public encryption israel people law com government\n",
      "Topic 5\n",
      "sq lj tm ml 4t 76 12 13 pp 04 pts 40 mu 37 mk 18 hz m_ wt mr uw 16 86 bj mw m3 mq 25 24 75 10 27 lk d9 9v 11 mv ah sl 17 45 55 wm 14 34 1d9 pl 145 max ax\n",
      "Topic 6\n",
      "monitor got drives windows pc power usa video bit price buy help disk hp used want 16 think speed apple work hard mac computer new need ve thanks problem distribution car good ca don use does scsi card know just like article writes university drive nntp host posting com edu\n",
      "Topic 7\n",
      "list access orbit dod large moon article water gordon cost program computer work pitt launch long systems low contact earth 30 good years like 50 center 93 science used ca year high time cs available 15 information use data research 20 1993 edu gov 10 00 new com nasa space\n",
      "Topic 8\n",
      "took bad killed problem long little came children better away started left day war told come com make writes let ll got really things work went want world armenians article ve years good armenian way say turkish didn right edu did going think know just time said don like people\n",
      "Topic 9\n",
      "pc dos computer run output application comp color problem user ac cs like unix display motif need thanks internet line number pub does help set email bit uk code image mit information data server graphics software version ftp using mail available key files window com program edu use windows file\n"
     ]
    }
   ],
   "source": [
    "topic_summaries(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.product(ngvec.shape) * 8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit ngvec.indices[ngvec.indptr[14]:ngvec.indptr[14+1]]\n",
    "%timeit ngvec[14, :].nonzero()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit X.toarray()[3, :45]\n",
    "%timeit X[3, :45].A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import lil_matrix\n",
    "lilX = lil_matrix(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit lilX[3, :45].A"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
