{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext line_profiler\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.sparse as spar\n",
    "import scipy.special as spec\n",
    "import sys\n",
    "from matplotlib import pyplot as plt\n",
    "from lda import LDA, _doc_update, _slice_doc_update\n",
    "from sklearn.decomposition import LatentDirichletAllocation as SKLDA\n",
    "\n",
    "import cProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "M = 100\n",
    "V = 1000\n",
    "X = np.random.binomial(1,.3, size=M*V).reshape(M,V)\n",
    "X = spar.csr_matrix(X, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For even a reasonable setup like 10K vocabulary, 5K documents and 20 topics, the size of the tensor indexed by\n",
    "# <document, word, topic> simply explodes to 7.5G. This is why we can't explicitly keep all of $\\phi$ in the memory.\n",
    "# Instead, we iterate over the documents one by one, and accumulate the phi parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lda = LDA()\n",
    "#cProfile.run(\"lda.fit(X)\")\n",
    "# %lprun -f lda.fit lda.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#b, g = lda.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "ng = fetch_20newsgroups(subset='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vec = CountVectorizer(max_df=.7, min_df=20, stop_words=\"english\")\n",
    "ngvec = vec.fit_transform(ng.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%lprun -f _slice_doc_update lda.fit(ngvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Epoch: 1\n",
      "Epoch: 2\n",
      "Epoch: 3\n",
      "Epoch: 4\n",
      "Epoch: 5\n",
      "Epoch: 6\n",
      "Epoch: 7\n",
      "Epoch: 8\n",
      "Epoch: 9\n",
      "CPU times: user 3.38 s, sys: 1.26 s, total: 4.65 s\n",
      "Wall time: 4min 12s\n"
     ]
    }
   ],
   "source": [
    "lda = LDA(K=10, n_jobs=8)\n",
    "%time b, g = lda.fit(ngvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lookup = lambda x : [k for k, v in vec.vocabulary_.items() if v == x]\n",
    "\n",
    "def topic_summaries(b):\n",
    "    bs = b.argsort()[:,-50:]\n",
    "    for i in range(10):\n",
    "        print \"Topic\", i\n",
    "        words = []\n",
    "        for j in range(bs.shape[1]):\n",
    "            words.append(lookup(bs[i,j])[0])\n",
    "        print \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print ng.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sklda = SKLDA(n_topics=5, learning_method=\"batch\", verbose=True)\n",
    "sklda.fit(ngvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topic_summaries(sklda.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0\n",
      "got cc andrew nhl people league columbia best news canada david know did player cmu turks time turkey world better armenia distribution reply games just play think good season baseball hockey like don armenians players armenian cs turkish nntp host posting game year team com university ca writes article edu\n",
      "Topic 1\n",
      "argument death claim christianity jews hell atheists human religious word caltech point said did way man moral world law evidence question true nntp like host truth christ life faith religion church just know christians posting bible university say christian does think believe don jesus article people com writes god edu\n",
      "Topic 2\n",
      "25 mw 94 04 p3 06 col m5 salmon pt hr gi 45 mas 14 dakota m4 ah 75 usd 225 mr sl mn om 68 34 d9 mq tm km 145 6e ei m3 tg m_ ml 4t lj wt z5 i4 bj 9v wm 1d9 pl max ax\n",
      "Topic 3\n",
      "33 36 louis chicago 01 division 37 35 pittsburgh hockey 93 34 38 gm new cup 21 03 team 20 montreal win game 02 pts 55 28 st 27 play 23 24 19 la 25 30 26 games period 15 18 17 13 14 vs 16 12 11 00 10\n",
      "Topic 4\n",
      "systems comp faq color uk format directory set cs net message info internet widget application nntp nasa dos sun display user unix motif pub information host code posting using db gov data graphics mit mail image access edu server available ftp use software windows program window files version file com\n",
      "Topic 5\n",
      "cc state 16 uk good sale used looking want using hard work cs apple ve ac disk video bit usa pc reply new help don mac mail problem need just scsi use computer windows card like does distribution ca know writes thanks article drive com nntp host posting university edu\n",
      "Topic 6\n",
      "13 section time book 40 cost henry computer contact earth 16 systems 14 toronto posting national launch center high 30 used 11 100 ca april available number research 12 data send 000 25 year 50 program list article nasa 15 use information university 20 1993 10 00 new space edu\n",
      "Topic 7\n",
      "got probably far course better car need lot used mr come com fact let sure use day world problem look point long little didn years ll new does things work writes really edu want ve right say going make did way said good time know think don like people just\n",
      "Topic 8\n",
      "policy number arab enforcement weapons firearms make secure like access control federal police does used just escrow information don distribution org clinton american privacy guns keys right nntp rights netcom host security state posting use israeli public chip people clipper law encryption gun israel article writes government edu key com\n",
      "Topic 9\n",
      "27 michael m3 mw mu 9v uw nntp mq host mr hp posting nasa ma d9 sun mv ride 17 au lk 45 air gov sl geb ai ah 14 ca org banks gordon wm 34 reply cs pitt dod bike 1d9 writes pl article 145 edu ax com max\n"
     ]
    }
   ],
   "source": [
    "topic_summaries(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.product(ngvec.shape) * 8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit ngvec.indices[ngvec.indptr[14]:ngvec.indptr[14+1]]\n",
    "%timeit ngvec[14, :].nonzero()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit X.toarray()[3, :45]\n",
    "%timeit X[3, :45].A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import lil_matrix\n",
    "lilX = lil_matrix(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit lilX[3, :45].A"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
